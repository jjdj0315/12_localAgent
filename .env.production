# Production Environment Configuration
# Local LLM Web Application for Local Government
#
# Usage: Copy to .env on production server and modify values
# CRITICAL: Update all secret keys and sensitive values!
# WARNING: DO NOT commit .env to version control

# =============================================================================
# APPLICATION
# =============================================================================
NODE_ENV=production
DEBUG=false
LOG_LEVEL=INFO

# =============================================================================
# DATABASE
# =============================================================================
# PostgreSQL connection (production)
# IMPORTANT: Update with production database credentials
DATABASE_URL=postgresql+asyncpg://llm_prod_user:CHANGE_ME_STRONG_PASSWORD@localhost:5432/llm_webapp_prod
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10

# For synchronous operations
DATABASE_URL_SYNC=postgresql://llm_prod_user:CHANGE_ME_STRONG_PASSWORD@localhost:5432/llm_webapp_prod

# =============================================================================
# SECURITY
# =============================================================================
# CRITICAL: Generate secure secret key
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=CHANGE_ME_GENERATE_SECURE_SECRET_KEY_32_BYTES

# Session security
SESSION_TIMEOUT_MINUTES=30
MAX_CONCURRENT_SESSIONS=3
BCRYPT_ROUNDS=12

# CORS (production - restrict to specific domains)
# Update with actual production domain
CORS_ORIGINS=["https://llm.yourorg.local", "https://llm-admin.yourorg.local"]
CORS_ALLOW_CREDENTIALS=true

# =============================================================================
# LLM CONFIGURATION
# =============================================================================
# Model path (production - absolute path recommended)
GGUF_MODEL_PATH=/opt/llm-webapp/models/qwen2.5-3b-instruct-q4_k_m.gguf
LLM_BACKEND=llama_cpp  # Options: llama_cpp (CPU), vllm (GPU)

# llama.cpp settings (production - optimize for your hardware)
N_CTX=2048  # Context window
N_THREADS=8  # Match CPU core count
N_GPU_LAYERS=0  # 0 = CPU only, set to 35 for full GPU offload

# Generation parameters (production - balanced)
TEMPERATURE=0.7
MAX_TOKENS=500
TOP_P=0.9

# =============================================================================
# EMBEDDING MODEL
# =============================================================================
EMBEDDING_MODEL_PATH=/opt/llm-webapp/models/paraphrase-multilingual-MiniLM-L12-v2
SENTENCE_TRANSFORMERS_HOME=/opt/llm-webapp/models

# =============================================================================
# STORAGE
# =============================================================================
# File upload settings (production)
UPLOAD_DIR=/var/lib/llm-webapp/uploads
MAX_UPLOAD_SIZE_MB=50
ALLOWED_EXTENSIONS=.pdf,.docx,.txt

# User quota (production - per FR-020)
USER_STORAGE_QUOTA_GB=10
AUTO_CLEANUP_ENABLED=true
INACTIVE_DAYS_THRESHOLD=30

# =============================================================================
# RATE LIMITING
# =============================================================================
# Production - strict limits per FR-031
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=500

# Login attempts (production - per FR-031)
MAX_LOGIN_ATTEMPTS=5
LOGIN_LOCKOUT_MINUTES=30

# =============================================================================
# ADVANCED FEATURES
# =============================================================================
# Safety Filter (FR-048, FR-049, FR-050)
ENABLE_SAFETY_FILTER=true
ENABLE_ML_FILTER=true  # Enable toxic-bert for production
ENABLE_PII_DETECTION=true

# ReAct Agent (FR-062, FR-086)
ENABLE_REACT_AGENT=true
MAX_REACT_SESSIONS=10
REACT_MAX_ITERATIONS=5

# Multi-Agent System (FR-070, FR-086)
ENABLE_MULTI_AGENT=true
MAX_AGENT_WORKFLOWS=5

# =============================================================================
# RESPONSE LIMITS
# =============================================================================
# Production - per FR-017, FR-041
MAX_RESPONSE_LENGTH=4000
MAX_DOCUMENT_RESPONSE_LENGTH=10000
MAX_CONVERSATION_MESSAGES=1000

# =============================================================================
# LOGGING
# =============================================================================
# Production - structured logging
LOG_FORMAT=json
LOG_FILE=/var/log/llm-webapp/app.log
LOG_ROTATION=daily
LOG_RETENTION_DAYS=90  # Keep logs for 3 months

# Audit logging (FR-083)
ENABLE_AUDIT_LOGGING=true
AUDIT_LOG_FILE=/var/log/llm-webapp/audit.log

# =============================================================================
# EXTERNAL SERVICES (Production)
# =============================================================================
# vLLM API (if using GPU backend)
# Uncomment and configure if using vLLM instead of llama.cpp
# VLLM_API_BASE=http://localhost:8001/v1
# VLLM_API_KEY=CHANGE_ME_SECURE_API_KEY

# =============================================================================
# FEATURE FLAGS (Production)
# =============================================================================
ENABLE_STREAMING=true
ENABLE_DOCUMENT_CHAT=true
ENABLE_TAG_AUTOSUGGESTION=true

# =============================================================================
# BACKUP (Production - FR-042)
# =============================================================================
BACKUP_DIR=/var/backups/llm-webapp
BACKUP_RETENTION_DAYS=30
AUTO_BACKUP_ENABLED=true

# =============================================================================
# FRONTEND (Production)
# =============================================================================
# Update with actual production URLs
NEXT_PUBLIC_API_URL=https://llm-api.yourorg.local
NEXT_PUBLIC_WS_URL=wss://llm-api.yourorg.local

# =============================================================================
# DOCKER (Production)
# =============================================================================
COMPOSE_PROJECT_NAME=llm_webapp_prod

# =============================================================================
# MONITORING (Production)
# =============================================================================
# Health check endpoints enabled
ENABLE_HEALTH_CHECKS=true
HEALTH_CHECK_INTERVAL_SECONDS=60

# Performance monitoring
ENABLE_PERFORMANCE_MONITORING=true
SLOW_QUERY_THRESHOLD_MS=1000

# =============================================================================
# SECURITY HEADERS (Production)
# =============================================================================
# Enforce security headers
ENABLE_HSTS=true
ENABLE_CSP=true
ENABLE_XSS_PROTECTION=true
ENABLE_FRAME_DENY=true

# =============================================================================
# AIR-GAPPED DEPLOYMENT (FR-001)
# =============================================================================
# Offline mode - disable all external network calls
HF_HUB_OFFLINE=1
TRANSFORMERS_OFFLINE=1
SENTENCE_TRANSFORMERS_HOME=/opt/llm-webapp/models

# =============================================================================
# PRODUCTION CHECKLIST
# =============================================================================
# Before deploying to production, ensure:
#
# [ ] SECRET_KEY changed to secure random value (32+ bytes)
# [ ] Database passwords changed to strong passwords
# [ ] CORS_ORIGINS restricted to production domains only
# [ ] All model files downloaded and paths configured
# [ ] Backup directory configured with sufficient space
# [ ] Log directory configured with rotation
# [ ] File upload directory configured with proper permissions
# [ ] Firewall rules configured (allow only necessary ports)
# [ ] SSL/TLS certificates installed (HTTPS)
# [ ] Admin account created via setup wizard
# [ ] All features tested in air-gapped environment
# [ ] Backup and restore procedures tested
# [ ] Health checks verified
# [ ] Audit logging verified
# [ ] Resource limits tested under load
# [ ] Security scan completed
#
# Refer to: docs/deployment/deployment-guide.md
#           docs/deployment/air-gapped-deployment.md
